<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>AIéŸ³å£°å…¥åŠ›ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆUI (ãƒ†ã‚­ã‚¹ãƒˆ/ãƒã‚¤ã‚¯å®Œå…¨å¯¾å¿œç‰ˆ)</title>
    <style>
        body {
            margin: 0;
            background: #0f0f0f;
            font-family: 'Segoe UI', sans-serif;
            overflow: hidden;
            color: #fff;
        }

        /* 1. æ³¢å½¢ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®èƒŒæ™¯ */
        #waveCanvas {
            position: fixed;
            top: 0; left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 0;
        }

        /* 2. UIã‚³ãƒ³ãƒ†ãƒŠã®èª¿æ•´ (ä¸‹éƒ¨ã«å›ºå®š) */
        #ui {
            position: absolute;
            bottom: 5%;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1.5rem;
            z-index: 10;
            transition: opacity 0.5s;
            opacity: 1; 
        }
        
        /* 3. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒªã‚¢ã®å®šç¾© */
        #status-area {
            padding: 15px 30px;
            background: rgba(0, 0, 0, 0.5);
            border-radius: 12px;
            backdrop-filter: blur(5px);
            box-shadow: 0 0 20px rgba(0, 255, 255, 0.3);
            color: #00ffff;
            font-size: 1.2rem;
            font-weight: bold;
            min-height: 40px; 
            display: flex;
            align-items: center;
            justify-content: center;
            white-space: pre-line; 
            text-align: center;
            line-height: 1.4;
            max-width: 80vw;
        }
        
        /* 4. å…¥åŠ›ã¨ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        #input-controls {
            display: flex;
            gap: 1rem;
            width: fit-content;
        }
        #messageInput {
            width: 400px;
            padding: 1rem;
            font-size: 1.2rem;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(0, 255, 255, 0.5);
            color: #fff;
            border-radius: 8px;
            backdrop-filter: blur(10px);
            outline: none;
        }
        #messageInput::placeholder {
            color: rgba(255, 255, 255, 0.4);
        }
        #sendBtn {
            font-size: 1rem; 
            text-align: center;
            width: auto; 
            padding: 1rem 2rem;
            color: #0f0f0f;
            background: #00ffff;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            backdrop-filter: blur(10px);
            transition: background 0.3s;
            box-shadow: 0 0 40px #00ffff;
            font-weight: bold;
            line-height: 1.2;
        }
        #sendBtn:hover {
            background: #33ffff;
        }
        
        /* 5. èªè­˜çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢ (Transcript) ã®ã‚¹ã‚¿ã‚¤ãƒ«
        #transcript {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #00ffaa;
            font-size: 2.1rem;
            font-weight: 400;
            text-align: center;
            max-width: 60vw;
            pointer-events: none; 
            z-index: 5;
            padding: 20px;
            background: rgba(9, 0, 0, 0.3);
            border-radius: 25px;
        } */

        /* 6. ã‚¿ãƒƒãƒ—æ¤œå‡ºã‚¨ãƒªã‚¢ (UIãƒˆã‚°ãƒ«ç”¨) */
        #tapArea {
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 1; 
        }
    </style>
</head>
<body>
    <canvas id="waveCanvas"></canvas>
    
    <div id="tapArea"></div>

    <div id="transcript"></div> 
    
    <div id="ui">
        <div id="status-area">
            ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼<br>
            é€šç§°GAIã‚¤ãƒã•ã‚“AI<br>
            AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...
        </div>

        <div id="input-controls">
            <input type="text" id="messageInput" placeholder="ã“ã“ã«æ–‡ç« ã‚’å…¥åŠ›ã™ã‚‹ã‹ã¾ãŸã¯ä½•ã‹è©±ã—ã¦ãã ã•ã„....">
            
            <button id="sendBtn">
                ãƒã‚¤ã‚¯/AIã‚’<br>
                ãƒªã‚»ãƒƒãƒˆã™ã‚‹
            </button>
        </div>
    </div>

    <script>
Â  Â  Â  Â  /* ---------- Canvasã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é–¢é€£ ---------- */
Â  Â  Â  Â  const canvas = document.getElementById("waveCanvas");
Â  Â  Â  Â  const ctx = canvas.getContext("2d");
Â  Â  Â  Â  canvas.width = window.innerWidth;
Â  Â  Â  Â  canvas.height = window.innerHeight;

Â  Â  Â  Â  let bars = [];
Â  Â  Â  Â  const barCount = 40;
Â  Â  Â  Â  const barWidth = 8;
Â  Â  Â  Â  const waveY = canvas.height / 2;
Â  Â  Â  Â  let dataArray; 
Â  Â  Â  Â  
Â  Â  Â  Â  let animationFrameId;
Â  Â  Â  Â  let isSpeaking = false; 
Â  Â  Â  Â  let isRecording = false; 

Â  Â  Â  Â  function createBars() {
Â  Â  Â  Â  Â  Â  bars = [];
Â  Â  Â  Â  Â  Â  const startX = canvas.width / 2 - (barCount * barWidth) / 2;
Â  Â  Â  Â  Â  Â  for (let i = 0; i < barCount; i++) {
Â  Â  Â  Â  Â  Â  Â  Â  bars.push({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x: startX + i * barWidth,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  height: 10,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color: "#00ffff"
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  function drawBars() {
Â  Â  Â  Â  Â  Â  bars.forEach(bar => {
Â  Â  Â  Â  Â  Â  Â  Â  ctx.fillStyle = bar.color;
Â  Â  Â  Â  Â  Â  Â  Â  ctx.fillRect(bar.x, waveY - bar.height / 2, barWidth - 2, bar.height); 
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  }

Â  Â  Â  Â  function animateBars() {
Â  Â  Â  Â  Â  Â  ctx.clearRect(0, 0, canvas.width, canvas.height);

Â  Â  Â  Â  Â  Â  if (isRecording && analyser && audioContext.state === 'running' && dataArray) {
Â  Â  Â  Â  Â  Â  Â  Â  analyser.getByteFrequencyData(dataArray);

Â  Â  Â  Â  Â  Â  Â  Â  const step = Math.floor(dataArray.length / barCount); 
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  bars.forEach((bar, i) => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const volume = dataArray[i * step] / 255; 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let targetHeight = volume * 180 + 20; 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bar.height += (targetHeight - bar.height) * 0.15;
Â  Â  Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  } else if (isSpeaking) {
Â  Â  Â  Â  Â  Â  Â  Â  // AIå¿œç­”ä¸­ã®æ“¬ä¼¼çš„ãªå‹•çš„æ³¢å½¢
Â  Â  Â  Â  Â  Â  Â  Â  bars.forEach(bar => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // 0ã‹ã‚‰80ã®ç¯„å›²ã§å‹•ãã€æœ€å°å€¤ã¯20
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let targetHeight = Math.random() * 80 + 20;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bar.height += (targetHeight - bar.height) * 0.15;
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  // å¾…æ©Ÿä¸­ã®æ§ãˆã‚ãªå‹•ã
Â  Â  Â  Â  Â  Â  Â  Â  bars.forEach(bar => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // 10ã‹ã‚‰20ã®ç¯„å›²ã§ã‚ãšã‹ã«å‹•ã
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let targetHeight = 10 + Math.random() * 10;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bar.height += (targetHeight - bar.height) * 0.15;
Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  drawBars();
Â  Â  Â  Â  Â  Â  animationFrameId = requestAnimationFrame(animateBars);
Â  Â  Â  Â  }

Â  Â  Â  Â  

Â  Â  Â  Â  /* --- 2. éŸ³å£°èª­ã¿ä¸Šã’/èªè­˜/APIé€£æºé–¢é€£ --- */
Â  Â  Â  Â  
Â  Â  Â  Â  // DOMè¦ç´ ã®å–å¾—
Â  Â  Â  Â  const statusArea = document.getElementById("status-area");
Â  Â  Â  Â  const sendBtn = document.getElementById("sendBtn"); 
Â  Â  Â  Â  const input = document.getElementById("messageInput"); 
Â  Â  Â  Â  const transcriptBox = document.getElementById('transcript');
Â  Â  Â  Â  const ui = document.getElementById('ui'); 
Â  Â  Â  Â  const tapArea = document.getElementById('tapArea'); 
Â  Â  Â  Â  
Â  Â  Â  Â  // APIè¨­å®š (ã”è‡ªèº«ã®ç’°å¢ƒã«åˆã‚ã›ã¦å¤‰æ›´ã—ã¦ãã ã•ã„)
Â  Â  Â  Â  const API_KEY = ""; 
Â  Â  Â  Â  const LLM_API_URL = "http://127.0.0.1:8001/generate";
Â  Â  Â  Â  const MQTT_API_URL = "http://127.0.0.1:8000/control"; 

Â  Â  Â  Â  // çŠ¶æ…‹ç®¡ç†å¤‰æ•°
Â  Â  Â  Â  const synth = window.speechSynthesis;
Â  Â  Â  Â  let audioContext, analyser, mediaStream;
Â  Â  Â  Â  let recognition = null; 
Â  Â  Â  Â  let currentTextToSpeak = ''; 
Â  Â  Â  Â  
Â  Â  Â  Â  // --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (è‰²ã®è£œé–“) ---
Â  Â  Â  Â  function hexToRgb(hex) {
Â  Â  Â  Â  Â  Â  const bigint = parseInt(hex.slice(1), 16);
Â  Â  Â  Â  Â  Â  const r = (bigint >> 16) & 255;
Â  Â  Â  Â  Â  Â  const g = (bigint >> 8) & 255;
Â  Â  Â  Â  Â  Â  const b = bigint & 255;
Â  Â  Â  Â  Â  Â  return [r, g, b];
Â  Â  Â  Â  }

Â  Â  Â  Â  function rgbToHex(r, g, b) {
Â  Â  Â  Â  Â  Â  const toHex = (c) => ('0' + Math.max(0, Math.min(255, c)).toString(16)).slice(-2);
Â  Â  Â  Â  Â  Â  return '#' + toHex(Math.round(r)) + toHex(Math.round(g)) + toHex(Math.round(b));
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  function startColorTransition(startColor, endColor, duration = 2000) {
Â  Â  Â  Â  Â  Â  const startTime = performance.now();
Â  Â  Â  Â  Â  Â  const startRgb = hexToRgb(startColor);
Â  Â  Â  Â  Â  Â  const endRgb = hexToRgb(endColor);

Â  Â  Â  Â  Â  Â  function interpolate(currentTime) {
Â  Â  Â  Â  Â  Â  Â  Â  const elapsed = currentTime - startTime;
Â  Â  Â  Â  Â  Â  Â  Â  const progress = Math.min(1, elapsed / duration);
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  const r = startRgb[0] + (endRgb[0] - startRgb[0]) * progress;
Â  Â  Â  Â  Â  Â  Â  Â  const g = startRgb[1] + (endRgb[1] - startRgb[1]) * progress;
Â  Â  Â  Â  Â  Â  Â  Â  const b = startRgb[2] + (endRgb[2] - startRgb[2]) * progress; 
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  const currentColor = rgbToHex(r, g, b);
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  statusArea.style.color = currentColor;
Â  Â  Â  Â  Â  Â  Â  Â  statusArea.style.boxShadow = `0 0 20px ${currentColor}80`;

Â  Â  Â  Â  Â  Â  Â  Â  if (progress < 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  requestAnimationFrame(interpolate);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  requestAnimationFrame(interpolate);
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  /* ---------- UI helpers ---------- */

Â  Â  Â  Â  function updateStatus(message, color = '#00ffff') {
Â  Â  Â  Â  Â  Â  statusArea.innerHTML = message; 
Â  Â  Â  Â  Â  Â  statusArea.style.color = color;
Â  Â  Â  Â  Â  Â  statusArea.style.boxShadow = `0 0 20px ${color}80`;
Â  Â  Â  Â  }

Â  Â  Â  Â  function setStandbyStatus() {
Â  Â  Â  Â  Â  Â  const standbyMsg = `
Â  Â  Â  Â  Â  Â  ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼
Â  Â  Â  Â  Â  Â  é€šç§°GAIã‚¤ãƒã•ã‚“AI
Â  Â  Â  Â  Â  Â  AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...
Â  Â  Â  Â  Â  Â  `;
Â  Â  Â  Â  Â  Â  updateStatus(standbyMsg.trim(), '#00ffff');
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  /* ---------- TTS (Speech Synthesis) ---------- */

        /**
         * LLMå¿œç­”ãªã©ã€AIã‹ã‚‰ã®æ­£å¼ãªå¿œç­”ã‚’èª­ã¿ä¸Šã’ã€çµ‚äº†å¾Œã«STTã‚’å†èµ·å‹•ã™ã‚‹
         */
Â  Â  Â  Â  function speak(text){ 
Â  Â  Â  Â  Â  Â  if(!text) return; 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  currentTextToSpeak = text; 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if(synth.speaking) synth.cancel(); 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  isSpeaking = true; 

Â  Â  Â  Â  Â  Â  const u = new SpeechSynthesisUtterance(text); 
Â  Â  Â  Â  Â  Â  u.lang='ja-JP'; 
Â  Â  Â  Â  Â  Â  u.rate=1.0; 
Â  Â  Â  Â  Â  Â  u.onstart=()=>{ 
Â  Â  Â  Â  Â  Â  Â  Â  const display = text.length > 20 ? text.substring(0, 20) + '...' : text;
Â  Â  Â  Â  Â  Â  Â  Â  const formattedStatus = `
Â  Â  Â  Â  Â  Â  ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼
Â  Â  Â  Â  Â  Â  é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”
Â  Â  Â  Â  Â  Â  ã€Œ${display}ã€
Â  Â  Â  Â  Â  Â  `;
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus(formattedStatus.trim(), '#00ffaa');
Â  Â  Â  Â  Â  Â  }; 
Â  Â  Â  Â  Â  Â  u.onend=()=>{ 
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false; 
Â  Â  Â  Â  Â  Â  Â  Â  currentTextToSpeak = ''; 
Â  Â  Â  Â  Â  Â  Â  Â  setStandbyStatus();
Â  Â  Â  Â  Â  Â  Â  Â  input.value = '';

Â  Â  Â  Â  Â  Â  Â  Â  // TTSçµ‚äº†å¾Œã€STTãŒåœæ­¢ã—ã¦ã„ã‚Œã°è‡ªå‹•ã§å†èµ·å‹•ã‚’è©¦ã¿ã‚‹
Â  Â  Â  Â  Â  Â  Â  Â  if (recognition && !isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recognition.start();
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } catch(e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn('Recognition restart failed after TTS:', e);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }; 
Â  Â  Â  Â  Â  Â  u.onerror = (e) => {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('TTS error:', e);
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  Â  Â  currentTextToSpeak = '';
Â  Â  Â  Â  Â  Â  Â  Â  setStandbyStatus();
Â  Â  Â  Â  Â  Â  Â  Â  input.value = '';
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  synth.speak(u); 
Â  Â  Â  Â  }

        /**
         * ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ™‚ã®å³æ™‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨èª­ã¿ä¸Šã’é–¢æ•°ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã«ç§»å‹•ï¼‰
         */
Â  Â  Â  Â  function speakSentence(text) {
Â  Â  Â  Â  Â  Â  // ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã‹ã€æ—¢ã«åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®èª­ã¿ä¸Šã’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„
Â  Â  Â  Â  Â  Â  if (text.trim() === '' || text === currentTextToSpeak) {
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  // æ–°ã—ã„èª­ã¿ä¸Šã’ãŒé–‹å§‹ã•ã‚Œã‚‹ã®ã§ã€ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
Â  Â  Â  Â  Â  Â  if (synth.speaking) {
Â  Â  Â  Â  Â  Â  Â  Â  synth.cancel();
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  currentTextToSpeak = text; // æ–°ã—ã„æ–‡ç« ã‚’è¨˜æ†¶

Â  Â  Â  Â  Â  Â  const utterance = new SpeechSynthesisUtterance(text); // const/let ã‚’ä½¿ç”¨
Â  Â  Â  Â  Â  Â  utterance.lang = 'ja-JP'; // æ—¥æœ¬èªã‚’è¨­å®š
Â  Â  Â  Â  Â  Â  utterance.rate = 1.0; 

Â  Â  Â  Â  Â  Â  utterance.onstart = () => {
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = true;
Â  Â  Â  Â  Â  Â  Â  Â  // èª­ã¿ä¸Šã’ä¸­ã®æ–‡ç« ã‚’ä¸€éƒ¨è¡¨ç¤º
Â  Â  Â  Â  Â  Â  Â  Â  const display = text.length > 20 ? text.substring(0, 20) + '...' : text;
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus(`æ–‡ç« ã‚’èª­ã¿ä¸Šã’ä¸­: ã€Œ${display}ã€`, '#00ffaa');
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  utterance.onend = () => {
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  Â  Â  // å³æ™‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒçµ‚ã‚ã£ã¦ã‚‚ã€å¾…æ©Ÿä¸­ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«æˆ»ã™ã ã‘
Â  Â  Â  Â  Â  Â  Â  Â  setStandbyStatus(); 
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  utterance.onerror = (event) => {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Speech Synthesis Error:', event);
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ', '#ff0000');
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  synth.speak(utterance);
Â  Â  Â  Â  }

Â  Â  Â  Â  /* ---------- Speech Recognition (Browser STT) & Audio Init ---------- */

Â  Â  Â  Â  function startBrowserRecognition() {
Â  Â  Â  Â  Â  Â  if (isRecording) return;
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Error: Speech Recognition not supported in this browser.', '#ff0000');
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (recognition) {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  Â  Â  Â  Â  recognition = null;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  recognition = new (window.webkitSpeechRecognition || window.SpeechRecognition)();
Â  Â  Â  Â  Â  Â  recognition.continuous = false; 
Â  Â  Â  Â  Â  Â  recognition.interimResults = true; 
Â  Â  Â  Â  Â  Â  recognition.lang = 'ja-JP';

Â  Â  Â  Â  Â  Â  recognition.onstart = () => {
Â  Â  Â  Â  Â  Â  Â  Â  isRecording = true;
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = true; 
Â  Â  Â  Â  Â  Â  Â  Â  const standbyMsg = `
Â  Â  Â  Â  Â  Â  Â  Â  Listening...
Â  Â  Â  Â  Â  Â  Â  Â  è©±ã—ã‹ã‘ã¦ãã ã•ã„...ï¼
Â  Â  Â  Â  Â  Â  Â  Â  `;
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus(standbyMsg.trim(), '#ffff00');
Â  Â  Â  Â  Â  Â  Â  Â  startColorTransition('#ffff00', '#00ffaa', 2000); 
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  // ç”»é¢ä¸­å¤®ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯éè¡¨ç¤ºã®ãŸã‚ã€å‡¦ç†ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
Â  Â  Â  Â  Â  Â  Â  Â  // transcriptBox.textContent = 'è©±ã—ã‹ã‘ã¦ãã ã•ã„...';
Â  Â  Â  Â  Â  Â  Â  Â  input.value = ''; 
Â  Â  Â  Â  Â  Â  Â  Â  if (synth.speaking) synth.cancel(); 
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  recognition.onresult = (event) => {
Â  Â  Â  Â  Â  Â  Â  Â  let interimTranscript = '';
Â  Â  Â  Â  Â  Â  Â  Â  let finalTranscript = '';

Â  Â  Â  Â  Â  Â  Â  Â  for (let i = event.resultIndex; i < event.results.length; ++i) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (event.results[i].isFinal) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  finalTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  interimTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  // ç”»é¢ä¸­å¤®ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¡¨ç¤ºã‚’éè¡¨ç¤ºã«ã™ã‚‹ãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
Â  Â  Â  Â  Â  Â  Â  Â  // transcriptBox.textContent = finalTranscript || interimTranscript; 
Â  Â  Â  Â  Â  Â  Â  Â  input.value = finalTranscript || interimTranscript; // å…¥åŠ›æ¬„ã«ã¯åæ˜ 
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  // ç™ºè©±çµ‚äº†ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å†ã‚¹ã‚¿ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯
Â  Â  Â  Â  Â  Â  const restartRecognition = () => {
Â  Â  Â  Â  Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  // TTSãŒå‹•ä½œä¸­ã§ãªã‘ã‚Œã°ã€å¾…æ©ŸçŠ¶æ…‹ã«æˆ»ã™
Â  Â  Â  Â  Â  Â  Â  Â  if (!synth.speaking) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false; 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  setStandbyStatus();
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // æ—¢ã«èªè­˜ãŒé–‹å§‹ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!isRecording && !synth.speaking) recognition.start(); 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (e.name !== 'InvalidStateError') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn('Recognition start failed:', e);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  }, 500); 
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  recognition.onend = () => {
Â  Â  Â  Â  Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  // TTSãŒå‹•ä½œã—ã¦ã„ãªã„å ´åˆã«é™ã‚Š isSpeaking ã‚’ false ã«
Â  Â  Â  Â  Â  Â  Â  Â  if (!synth.speaking) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false; 
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  const finalPrompt = input.value.trim(); // transcriptBoxã®ä»£ã‚ã‚Šã«input.valueã‚’ä½¿ã†
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  // èªè­˜çµæœãŒç©ºã§ãªã„ã€ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ãªã„å ´åˆã®ã¿å‡¦ç†
Â  Â  Â  Â  Â  Â  Â  Â  if (finalPrompt && finalPrompt.length > 1 && !finalPrompt.startsWith("è©±ã—ã‹ã‘ã¦ãã ã•ã„") && !finalPrompt.startsWith("ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:")) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Processing response...', '#00ffaa');
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // LLMå‡¦ç†ä¸­ã«STTãŒè‡ªå‹•ã§å†èµ·å‹•ã—ãªã„ã‚ˆã†ã«ã€.finallyã§restartRecognitionã‚’å‘¼ã¶
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processRecognitionResult(finalPrompt).finally(() => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // TTSãŒçµ‚äº†ã—ãŸå¾Œã«å†èµ·å‹•ã•ã›ã‚‹ (speaké–¢æ•°å†…ã®onendã§ã‚‚å®Ÿæ–½ã•ã‚Œã‚‹ãŸã‚å†—é•·ã§ã¯ã‚ã‚‹ãŒå¿µã®ãŸã‚)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!synth.speaking) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition(); 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // input.value = ''; // onresultã§ã‚¯ãƒªã‚¢ã•ã‚Œã‚‹ãŸã‚ä¸è¦
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  recognition.onerror = (event) => {
Â  Â  Â  Â  Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Speech Recognition Error:', event.error);
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  if (event.error !== 'not-allowed' && event.error !== 'aborted') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  Â  Â  Â  Â  } else if (event.error === 'aborted') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // æ„å›³çš„ãªåœæ­¢ï¼ˆstop()å‘¼ã³å‡ºã—ï¼‰ã®å ´åˆã‚‚ã‚ã‚‹ãŸã‚ã€å†èµ·å‹•
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition(); 
Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Error: Microphone permission denied or failed.', '#ff0000');
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.start();
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.warn('Initial recognition start failed:', e);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  async function initAudioAndSTT(){
Â  Â  Â  Â  Â  Â  if(analyser) {
Â  Â  Â  Â  Â  Â  Â  Â  startBrowserRecognition();
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  updateStatus('Requesting microphone access...');

Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  audioContext = new (window.AudioContext || window.webkitAudioContext)();
Â  Â  Â  Â  Â  Â  Â  Â  analyser = audioContext.createAnalyser();
Â  Â  Â  Â  Â  Â  Â  Â  analyser.fftSize = 2048;
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  dataArray = new Uint8Array(analyser.frequencyBinCount);
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
Â  Â  Â  Â  Â  Â  Â  Â  const sourceNode = audioContext.createMediaStreamSource(mediaStream);
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  sourceNode.connect(analyser);

Â  Â  Â  Â  Â  Â  Â  Â  startBrowserRecognition();

Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Listening...', '#ffff00');
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Audio initialization failed:', e);
Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Error: Microphone access denied or failed to initialize.', '#ff0000');
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  /**
Â  Â  Â  Â  Â * FastAPI/MQTTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
Â  Â  Â  Â  Â */
Â  Â  Â  Â  async function sendIoTCommand(command) {
Â  Â  Â  Â  Â  Â  updateStatus(`Executing IoT command: ${command}...`, '#00ffaa');
Â  Â  Â  Â  Â  Â  // ç”»é¢ä¸­å¤®ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¡¨ç¤ºã‚’éè¡¨ç¤ºã«ã™ã‚‹ãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
Â  Â  Â  Â  Â  Â  // transcriptBox.textContent = `IoTã‚³ãƒãƒ³ãƒ‰: ${command} ã‚’å®Ÿè¡Œä¸­...`;
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  const response = await fetch(MQTT_API_URL, {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' },
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify({ command: command })
Â  Â  Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  Â  Â  const data = await response.json();

Â  Â  Â  Â  Â  Â  Â  Â  if (response.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const successMsg = `æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚${command === 'ON' ? 'é›»æ°—ã‚’ã¤ã‘ã¾ã—ãŸ' : 'é›»æ°—ã‚’æ¶ˆã—ã¾ã—ãŸ'}ã€‚`;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  speak(successMsg);
Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const detail = data.detail || "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼";
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const errorMsg = `ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚IoTã‚³ãƒãƒ³ãƒ‰ '${command}' ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: ${detail}`;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  speak(errorMsg);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  } catch (error) {
Â  Â  Â  Â  Â  Â  Â  Â  const networkErrorMsg = `ğŸ”´ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: IoTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ (${error.message})`;
Â  Â  Â  Â  Â  Â  Â  Â  speak(networkErrorMsg);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }


Â  Â  Â  Â  /* ---------- çµ±åˆã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° (IoT or LLM) ---------- */

Â  Â  Â  Â  async function processRecognitionResult(finalPrompt) {
Â  Â  Â  Â  Â  Â  // 1. IoTã‚³ãƒãƒ³ãƒ‰ã®åˆ¤å®šã¨æŒ¯ã‚Šåˆ†ã‘
Â  Â  Â  Â  Â  Â  const lowerPrompt = finalPrompt.toLowerCase();
Â  Â  Â  Â  Â  Â  let iotCommand = null;

Â  Â  Â  Â  Â  Â  if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã¤ã‘') || lowerPrompt.includes('ã‚ªãƒ³') || lowerPrompt.includes('ç‚¹ã‘'))) {
Â  Â  Â  Â  Â  Â  Â  Â  iotCommand = 'ON';
Â  Â  Â  Â  Â  Â  } else if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã‘ã—') || lowerPrompt.includes('ã‚ªãƒ•') || lowerPrompt.includes('æ¶ˆã—'))) {
Â  Â  Â  Â  Â  Â  Â  Â  iotCommand = 'OFF';
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (iotCommand) {
Â  Â  Â  Â  Â  Â  Â  Â  await sendIoTCommand(iotCommand);
Â  Â  Â  Â  Â  Â  Â  Â  return; 
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 2. LLMå¿œç­”ç”Ÿæˆï¼ˆIoTã‚³ãƒãƒ³ãƒ‰ã§ãªã‹ã£ãŸå ´åˆï¼‰
Â  Â  Â  Â  Â  Â  await generateAndSpeakResponse(finalPrompt);
Â  Â  Â  Â  }


Â  Â  Â  Â  /* ---------- LLM (Gemini) API & TTS é€£æº ---------- */
Â  Â  Â  Â  async function generateAndSpeakResponse(prompt) {
Â  Â  Â  Â  Â  Â  updateStatus('Generating response (via FastAPI)...', '#00ffaa');
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const cleanedPrompt = prompt.replace(/^ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:\s*/, '').trim();
Â  Â  Â  Â  Â  Â  if (!cleanedPrompt) {
Â  Â  Â  Â  Â  Â  Â  Â  return; 
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  const systemInstruction = "ã‚ãªãŸã¯ã€Œã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“ã€ã¨ã„ã†åå‰ã®KS-903model8800-a1-90dã¨ã„ã†éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ã€ç°¡æ½”ã‹ã¤ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚";

Â  Â  Â  Â  Â  Â  const payload = {
Â  Â  Â  Â  Â  Â  Â  Â  prompt: cleanedPrompt,
Â  Â  Â  Â  Â  Â  Â  Â  contents: [{ parts: [{ text: cleanedPrompt }] }],
Â  Â  Â  Â  Â  Â  Â  Â  systemInstruction: { parts: [{ text: systemInstruction }] },
Â  Â  Â  Â  Â  Â  Â  Â  tools: [{ "google_search": {} }], 
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const MAX_RETRIES = 3;
Â  Â  Â  Â  Â  Â  let responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIã®KS-903model8800-a1-90då¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";

Â  Â  Â  Â  Â  Â  for (let i = 0; i < MAX_RETRIES; i++) {
Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const response = await fetch(LLM_API_URL, {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' },
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify(payload)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (!response.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const errorData = await response.json().catch(() => ({ detail: `HTTP ${response.status} Error.` }));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  throw new Error(`FastAPI Error! Status: ${response.status}. Detail: ${errorData.detail}`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const result = await response.json();
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (result && result.text) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  responseText = result.text;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break; 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â throw new Error("Empty response or invalid JSON structure from FastAPI.");
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error(`FastAPI call error on attempt ${i + 1}:`, e);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (i === MAX_RETRIES - 1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIKS-903model8800-a1-90dã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Generaltebãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ (ãƒãƒ¼ãƒˆ8001) ã®å®Ÿè¡ŒçŠ¶æ…‹ã¨APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  const delay = 2 ** i * 1000 + Math.random() * 500;
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  await new Promise(resolve => setTimeout(resolve, delay));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  updateStatus('Speaking response...', '#00ffaa');
Â  Â  Â  Â  Â  Â  speak(responseText); 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  return Promise.resolve();
Â  Â  Â  Â  }

Â  Â  Â  Â  /* ---------- ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã®çµ±åˆã¨å®šç¾© ---------- */

Â  Â  Â  Â  // ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¿½åŠ  (Enterã‚­ãƒ¼ã§å‡¦ç†)
Â  Â  Â  Â  input.addEventListener('keydown', (e) => {
Â  Â  Â  Â  Â  Â  // Enterã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸå ´åˆï¼ˆæ”¹è¡Œã‚’é˜²ãã€å‡¦ç†ã‚’é–‹å§‹ï¼‰
Â  Â  Â  Â  Â  Â  if (e.key === 'Enter' && !e.shiftKey && !e.ctrlKey && !e.altKey) {
Â  Â  Â  Â  Â  Â  Â  Â  e.preventDefault(); 
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  const textPrompt = input.value.trim();
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  if (textPrompt) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // éŸ³å£°èªè­˜ãŒå®Ÿè¡Œä¸­ã®å ´åˆã¯å¼·åˆ¶åœæ­¢
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (recognition && isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  recognition.stop(); 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // TTSã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ï¼ˆå³æ™‚èª­ã¿ä¸Šã’ã‚’åœæ­¢ï¼‰
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if(synth.speaking) synth.cancel(); 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // å‡¦ç†ã‚’å„ªå…ˆ
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  updateStatus('Processing text input...', '#ffff00');
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // ç”»é¢ä¸­å¤®ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¡¨ç¤ºã‚’éè¡¨ç¤ºã«ã™ã‚‹ãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // transcriptBox.textContent = textPrompt; 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // LLMå‡¦ç†ã‚’å®Ÿè¡Œ
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processRecognitionResult(textPrompt).catch(error => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error("Text input processing failed:", error);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }).finally(() => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  // input.valueã¯speakã®onendã§ã‚¯ãƒªã‚¢ã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });

Â  Â  Â  Â  // ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ãŸã³ã«ç¾åœ¨ã®å†…å®¹ã‚’èª­ã¿ä¸Šã’ã‚‹æ©Ÿèƒ½ã®è¿½åŠ  (TTSå³æ™‚ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼)
Â  Â  Â  Â  input.addEventListener('input', (event) => {
Â  Â  Â  Â  Â  Â  const currentText = input.value.trim();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // éŸ³å£°èªè­˜ãŒå®Ÿè¡Œä¸­ã§ãªã„ã€ã‹ã¤ã€AIãŒå¿œç­”ä¸­ã§ãªã„å ´åˆã«ã®ã¿å®Ÿè¡Œ
Â  Â  Â  Â  Â  Â  // ã‹ã¤ã€ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆãŒèª­ã¿ä¸Šã’ä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ç•°ãªã‚‹å ´åˆ
Â  Â  Â  Â  Â  Â  if (!isRecording && !isSpeaking && currentText.length > 0 && currentText !== currentTextToSpeak) {
Â  Â  Â  Â  Â  Â  Â  Â  // â˜…â˜…â˜… ã“ã“ã‚’ speakSentence ã«å¤‰æ›´ â˜…â˜…â˜…
Â  Â  Â  Â  Â  Â  Â  Â  speakSentence(currentText); 
Â  Â  Â  Â  Â  Â  } else if (currentText.length === 0 && synth.speaking) {
Â  Â  Â  Â  Â  Â  Â  Â  // ãƒ†ã‚­ã‚¹ãƒˆãŒå…¨ã¦å‰Šé™¤ã•ã‚Œã€ã‹ã¤èª­ã¿ä¸Šã’ä¸­ã®å ´åˆã¯ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¦å¾…æ©ŸçŠ¶æ…‹ã«æˆ»ã™
Â  Â  Â  Â  Â  Â  Â  Â  synth.cancel();
Â  Â  Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  Â  Â  setStandbyStatus();
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });

Â  Â  Â  Â  // ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã®æ©Ÿèƒ½ (STTã¨TTSã®å¼·åˆ¶åœæ­¢ã¨å†èµ·å‹•)
Â  Â  Â  Â  sendBtn.addEventListener("click", () => {
Â  Â  Â  Â  Â  Â  if (recognition) {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  Â  Â  Â  Â  recognition = null;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if(synth.speaking) synth.cancel(); 

Â  Â  Â  Â  Â  Â  // ç”»é¢ä¸­å¤®ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¡¨ç¤ºã‚’éè¡¨ç¤ºã«ã™ã‚‹ãŸã‚ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
Â  Â  Â  Â  Â  Â  // transcriptBox.textContent='ãƒªã‚»ãƒƒãƒˆä¸­...'; 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // isSpeakingã¨isRecordingã‚’å¼·åˆ¶çš„ã«falseã«
Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  isRecording = false;

Â  Â  Â  Â  Â  Â  initAudioAndSTT();
Â  Â  Â  Â  Â  Â  updateStatus('ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚ãƒã‚¤ã‚¯å…¥åŠ›ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™...'); 
Â  Â  Â  Â  });


Â  Â  Â  Â  // UI ãƒˆã‚°ãƒ«æ©Ÿèƒ½ (ç”»é¢ã‚¿ãƒƒãƒ—) 
Â  Â  Â  Â  let uiVisible = true; 
Â  Â  Â  Â  tapArea.addEventListener('click', (e) => {
Â  Â  Â  Â  Â  Â  // ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã¸ã®ã‚¿ãƒƒãƒ—ã¯ç„¡è¦–
Â  Â  Â  Â  Â  Â  if (e.target.closest('#input-controls')) {
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  uiVisible = !uiVisible;
Â  Â  Â  Â  Â  Â  if (uiVisible) {
Â  Â  Â  Â  Â  Â  Â  Â  ui.style.opacity = 1; 
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  ui.style.opacity = 0; 
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });

Â  Â  Â  Â  /* ---------- Start-up ---------- */
Â  Â  Â  Â  window.onload = function() {
Â  Â  Â  Â  Â  Â  createBars();
Â  Â  Â  Â  Â  Â  animateBars();
Â  Â  Â  Â  Â  Â  initAudioAndSTT(); // ãƒã‚¤ã‚¯åˆæœŸåŒ–ã¨STTã‚’è‡ªå‹•ã§é–‹å§‹
Â  Â  Â  Â  Â  Â  setStandbyStatus();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // UIã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¡¨ç¤ºçŠ¶æ…‹ã«ã™ã‚‹
Â  Â  Â  Â  Â  Â  ui.style.opacity = 1; 
Â  Â  Â  Â  Â  Â  uiVisible = true;
Â  Â  Â  Â  }
Â  Â  </script>
</body>
</html>